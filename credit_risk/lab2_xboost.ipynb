{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "envml",
   "display_name": "Python ML",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ML.credit_risk.pipeline import make_train_pipeline\n",
    "from ML.credit_risk.pipeline.data_operations import *\n",
    "from ML.credit_risk.pipeline.read_data import read_data_train\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = read_data_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = make_train_pipeline()\n",
    "data = train_pipeline.fit_transform(data_original.copy(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_train_data(data, [\"TARGET\"], 42, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = y_train[\"TARGET\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = XGBClassifier(\n",
    "    max_depth = 5,\n",
    "    learning_rate = 1,\n",
    "    scale_pos_weight = target_counts[0] / target_counts[1],\n",
    "    objective = 'binary:logistic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\coding\\Jupyter_notebooks\\envML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\coding\\Jupyter_notebooks\\envML\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "[20:36:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=2, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=11.387386984155402,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "booster.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NAME_INCOME_TYPE_Businessman\t0.0\nNAME_INCOME_TYPE_Student\t0.0043802810832858086\n"
     ]
    }
   ],
   "source": [
    "for col, importance in zip(x_train.columns, booster.feature_importances_):\n",
    "    if importance < 0.01:\n",
    "        print(f\"{col}\\t{importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "true positive: 1360\ntrue negative: 18243\nfalse positive: 10026\nfalse negative: 1123\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1961208450501118"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "f1_score(y_test, booster.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6292114900678327,\n",
       " array([0.62933843, 0.62510359, 0.61236054, 0.6330565 , 0.62043813,\n",
       "        0.64169985, 0.62804991, 0.63231448, 0.62705365, 0.64269982]))"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "cross_validate(booster, x_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "model_path = Path(\"ML/credit_risk/xgboost_roc_auc_0-63.model\")\n",
    "pickle.dump(booster, model_path.open(\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}